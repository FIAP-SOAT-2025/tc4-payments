name: Payments Deploy

on:
  push:
    branches: [main]
    paths: ['/**']
  pull_request:
    branches: [main]
    paths: ['/**']
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'apply'
        type: choice
        options:
          - apply
          - destroy

env:
  AWS_REGION: us-east-1
  TF_VERSION: 1.6.0
  EKS_CLUSTER_NAME: eks-tc3-g38-lanchonete
  MICROSERVICE_NAME: payments
  NAMESPACE: lanchonete-payments

jobs:
  check-dependencies:
    name: Check Infrastructure Dependencies
    runs-on: ubuntu-latest
    environment: production
    outputs:
      infra-exists: ${{ steps.check-deps.outputs.infra-exists }}

    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Check EKS Cluster Exists
        id: check-deps
        run: |
          # Verifica se o cluster EKS existe antes de tentar fazer deploy
          if aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} &> /dev/null; then
            echo "infra-exists=true" >> $GITHUB_OUTPUT
            echo "âœ… EKS cluster '${{ env.EKS_CLUSTER_NAME }}' found"
          else
            echo "infra-exists=false" >> $GITHUB_OUTPUT
            echo "âŒ EKS cluster '${{ env.EKS_CLUSTER_NAME }}' not found"
            echo "âš ï¸  You need to deploy terraform-infra first!"
            exit 1
          fi

  terraform-apply:
    name: Deploy Payments Microservice
    needs: [check-dependencies]
    runs-on: ubuntu-latest
    if: needs.check-dependencies.outputs.infra-exists == 'true' && (github.event.inputs.action == 'apply' || github.event.inputs.action == '')
    defaults:
      run:
        working-directory: ./terraform
    environment: production
    env:
      # VariÃ¡veis de ambiente especÃ­ficas do Payments
      TF_VAR_db_user: ${{ secrets.DB_USER }}
      TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
      TF_VAR_db_name: ${{ secrets.DB_NAME }}
      TF_VAR_mercadopago_access_token: ${{ secrets.MERCADOPAGO_ACCESS_TOKEN }}
      TF_VAR_docker_image: ${{ secrets.DOCKERHUB_USERNAME }}/payments
      TF_VAR_namespace: ${{ env.NAMESPACE }}
      TF_VAR_microservice_name: ${{ env.MICROSERVICE_NAME }}

    steps:
      - name: ðŸ“¦ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: ðŸ”‘ Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: âš™ï¸ Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: ðŸ”— Configure kubectl for EKS
        run: |
          aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }}
          echo "âœ… Kubeconfig configured for cluster: ${{ env.EKS_CLUSTER_NAME }}"
          kubectl get nodes

      - name: ðŸš€ Terraform Init
        run: terraform init

      - name: ðŸ“‹ Terraform Plan
        run: |
          terraform plan -out=tfplan
          echo "ðŸ“ Plan generated successfully"

      - name: âœ… Terraform Apply
        run: |
          terraform apply -auto-approve tfplan
          echo "âœ… Terraform apply completed"

      - name: ðŸ” Verify Payments Deployment
        run: |
          echo "â³ Waiting for Payments pods to be ready..."
          kubectl wait --for=condition=ready pod \
            -l app=${{ env.MICROSERVICE_NAME }} \
            -n ${{ env.NAMESPACE }} \
            --timeout=300s || echo "âš ï¸  Timeout waiting for pods, checking status..."

          echo "ðŸ“Š Pods status:"
          kubectl get pods -n ${{ env.NAMESPACE }}

          echo "ðŸ“Š Services status:"
          kubectl get services -n ${{ env.NAMESPACE }}

      - name: ðŸŒ Get Service URL
        id: get-url
        run: |
          echo "â³ Waiting for LoadBalancer to get external IP..."
          sleep 60

          # Tenta pegar o hostname do LoadBalancer
          LB_HOSTNAME=$(kubectl get svc ${{ env.MICROSERVICE_NAME }}-service \
            -n ${{ env.NAMESPACE }} \
            -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")

          if [ -n "$LB_HOSTNAME" ]; then
            echo "service-url=http://$LB_HOSTNAME" >> $GITHUB_OUTPUT
            echo "âœ… LoadBalancer URL: http://$LB_HOSTNAME"
          else
            echo "service-url=pending" >> $GITHUB_OUTPUT
            echo "âš ï¸  LoadBalancer still provisioning..."
          fi

      - name: ðŸ¥ Health Check
        if: steps.get-url.outputs.service-url != 'pending'
        run: |
          URL="${{ steps.get-url.outputs.service-url }}/health"
          echo "ðŸ” Testing health endpoint: $URL"

          for i in {1..5}; do
            if curl -f $URL; then
              echo "âœ… Health check passed!"
              break
            else
              echo "âš ï¸  Attempt $i/5 failed, retrying in 30s..."
              sleep 30
            fi
          done

      - name: ðŸ“ Deployment Summary
        run: |
          echo "================================"
          echo "ðŸŽ‰ Payments Microservice Deployed!"
          echo "================================"
          echo "ðŸ“¦ Microservice: ${{ env.MICROSERVICE_NAME }}"
          echo "ðŸ·ï¸  Namespace: ${{ env.NAMESPACE }}"
          echo "â˜¸ï¸  Cluster: ${{ env.EKS_CLUSTER_NAME }}"
          echo "ðŸŒ Region: ${{ env.AWS_REGION }}"
          echo "ðŸŒ Service URL: ${{ steps.get-url.outputs.service-url }}"
          echo "================================"

  terraform-destroy:
    name: Destroy Payments Microservice
    runs-on: ubuntu-latest
    if: github.event.inputs.action == 'destroy'
    defaults:
      run:
        working-directory: ./terraform
    environment: production
    env:
      TF_VAR_db_user: ${{ secrets.DB_USER }}
      TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
      TF_VAR_db_name: ${{ secrets.DB_NAME }}
      TF_VAR_mercadopago_access_token: ${{ secrets.MERCADOPAGO_ACCESS_TOKEN }}
      TF_VAR_docker_image: ${{ secrets.DOCKERHUB_USERNAME }}/payments
      TF_VAR_namespace: ${{ env.NAMESPACE }}
      TF_VAR_microservice_name: ${{ env.MICROSERVICE_NAME }}

    steps:
      - name: ðŸ“¦ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: ðŸ”‘ Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: âš™ï¸ Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: ðŸ” Check if EKS cluster exists
        id: check-cluster
        run: |
          if aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} &> /dev/null; then
            echo "cluster-exists=true" >> $GITHUB_OUTPUT
            echo "âœ… EKS cluster exists, configuring kubectl..."
          else
            echo "cluster-exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸  EKS cluster not found, skipping kubectl configuration"
          fi

      - name: ðŸ”— Configure kubectl
        if: steps.check-cluster.outputs.cluster-exists == 'true'
        run: |
          aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }}
          kubectl get nodes || echo "âš ï¸  Failed to get nodes, but continuing..."

      - name: ðŸš€ Terraform Init
        run: terraform init

      - name: ðŸ“‹ Terraform Plan Destroy
        run: terraform plan -destroy -no-color
        continue-on-error: true

      - name: ðŸ—‘ï¸ Terraform Destroy
        run: |
          echo "ðŸ—‘ï¸  Destroying Payments microservice infrastructure..."
          terraform destroy -auto-approve

      - name: âœ… Verify Destruction
        run: |
          echo "ðŸ” Verifying resource destruction..."
          if [ "${{ steps.check-cluster.outputs.cluster-exists }}" == "true" ]; then
            kubectl get pods -n ${{ env.NAMESPACE }} 2>/dev/null || echo "âœ… Namespace destroyed or not found"
          fi
          echo "âœ… Payments destroy job completed"
